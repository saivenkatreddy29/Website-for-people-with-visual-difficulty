{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f68100",
   "metadata": {},
   "source": [
    "## Simulating Eye Sight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51028036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Output File NameS3A3175\n",
      "Enter the spherical power (in diopters): 3\n",
      "Enter the cylindrical power (in diopters): 2\n",
      "Enter the axis orientation (in degrees): 175\n",
      "Enter the number of images to process: 10\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def simulate_vd(image, spherical_power, cylindrical_power, axis_orientation):\n",
    "    # Apply spherical correction\n",
    "    simulated_image = image.copy()\n",
    "    if spherical_power != 0:\n",
    "        if spherical_power < 0:\n",
    "            # Simulate myopia (nearsightedness)\n",
    "            blur_kernel_size = int(abs(spherical_power) * 4 + 1)\n",
    "            blur_kernel_size = blur_kernel_size if blur_kernel_size % 2 == 1 else blur_kernel_size + 1\n",
    "            simulated_image = cv2.GaussianBlur(simulated_image, (blur_kernel_size, blur_kernel_size), 0)\n",
    "        else:\n",
    "            # Simulate hypermetropia (farsightedness)\n",
    "            focal_length = 1 / spherical_power\n",
    "            simulated_image = cv2.resize(simulated_image, None, fx=focal_length, fy=focal_length, interpolation=cv2.INTER_LINEAR)\n",
    "            simulated_image = cv2.resize(simulated_image, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Apply cylindrical correction\n",
    "    if cylindrical_power != 0:\n",
    "        kernel_size = int(abs(cylindrical_power) * 4 + 1)\n",
    "        kernel_size = kernel_size if kernel_size % 2 == 1 else kernel_size + 1\n",
    "        sigma = kernel_size / 4\n",
    "        lambd = kernel_size / 2\n",
    "        gamma = 0.5\n",
    "        kernel = cv2.getGaborKernel((kernel_size, kernel_size), sigma, np.deg2rad(axis_orientation), lambd, gamma, 0, ktype=cv2.CV_32F)\n",
    "        kernel /= 1.5 * kernel.sum()\n",
    "        simulated_image = cv2.filter2D(simulated_image, -1, kernel)\n",
    "    \n",
    "    return simulated_image\n",
    "\n",
    "def process_images(input_folder, output_folder, spherical_power, cylindrical_power, axis_orientation, num_images):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Get a list of image files in the input folder\n",
    "    image_files = glob.glob(os.path.join(input_folder, '*.png'))\n",
    "    image_files += glob.glob(os.path.join(input_folder, '*.jpg'))  # Add support for jpg files\n",
    "    \n",
    "    # Process specified number of images\n",
    "    for i, image_file in enumerate(image_files[:num_images]):\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_file)\n",
    "        \n",
    "        # Simulate visual defect\n",
    "        simulated_image = simulate_vd(image, spherical_power, cylindrical_power, axis_orientation)\n",
    "        \n",
    "        # Construct the output file path\n",
    "        output_file = os.path.join(output_folder, f'Simulated_Image_{i+1}.png')\n",
    "        \n",
    "        # Save the simulated image\n",
    "        cv2.imwrite(output_file, simulated_image)\n",
    "\n",
    "# Get input from the user\n",
    "input_folder = 'flickr30k_images'\n",
    "output_folder = input(\"Enter the Output File Name\")\n",
    "spherical_power = float(input(\"Enter the spherical power (in diopters): \"))\n",
    "cylindrical_power = float(input(\"Enter the cylindrical power (in diopters): \"))\n",
    "axis_orientation = float(input(\"Enter the axis orientation (in degrees): \"))\n",
    "num_images = int(input(\"Enter the number of images to process: \"))\n",
    "\n",
    "# Process the images with the given metrics\n",
    "process_images(input_folder, output_folder, spherical_power, cylindrical_power, axis_orientation, num_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19071cd0",
   "metadata": {},
   "source": [
    "## Correcting Eye Sight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6063fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def apply_correction(image, spherical_power, cylindrical_power, axis_orientation):\n",
    "    # Define the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Create a meshgrid of coordinates\n",
    "    x, y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "    # Convert spherical and cylindrical power to meters\n",
    "    spherical_power *= -0.001  # Convert diopters to meters\n",
    "    cylindrical_power *= -0.001  # Convert diopters to meters\n",
    "\n",
    "    # Convert cylindrical power and axis orientation to radians\n",
    "    cylindrical_power_rad = cylindrical_power * 2 * np.pi\n",
    "    angle_rad = np.deg2rad(axis_orientation)\n",
    "\n",
    "    # Compute the distorted coordinates\n",
    "    x_distorted = x - width / 2\n",
    "    y_distorted = y - height / 2\n",
    "\n",
    "    x_corrected = x_distorted + spherical_power * x_distorted + cylindrical_power_rad * np.cos(2 * angle_rad) * x_distorted + cylindrical_power_rad * np.sin(2 * angle_rad) * y_distorted\n",
    "    y_corrected = y_distorted + spherical_power * y_distorted + cylindrical_power_rad * np.sin(2 * angle_rad) * x_distorted + cylindrical_power_rad * np.cos(2 * angle_rad) * y_distorted\n",
    "\n",
    "    x_corrected += width / 2\n",
    "    y_corrected += height / 2\n",
    "\n",
    "    # Interpolate the corrected coordinates to obtain the corrected image\n",
    "    corrected_image = cv2.remap(image, x_corrected.astype(np.float32), y_corrected.astype(np.float32), cv2.INTER_LINEAR)\n",
    "\n",
    "    return corrected_image\n",
    "\n",
    "def save_images(image, corrected_image, output_folder, index):\n",
    "    # Save original image\n",
    "    original_path = os.path.join(output_folder, f'Original_Image_{index}.jpg')\n",
    "    cv2.imwrite(original_path, image)\n",
    "\n",
    "    # Save corrected image\n",
    "    corrected_path = os.path.join(output_folder, f'Corrected_Image_{index}.jpg')\n",
    "    cv2.imwrite(corrected_path, corrected_image)\n",
    "\n",
    "def process_images(input_folder, output_folder, spherical_power, cylindrical_power, axis_orientation, num_images):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Get a list of image files in the input folder\n",
    "    image_files = glob.glob(os.path.join(input_folder, '*.png'))\n",
    "    image_files += glob.glob(os.path.join(input_folder, '*.jpg'))  # Add support for jpg files\n",
    "    \n",
    "    # Process specified number of images\n",
    "    for i, image_file in enumerate(image_files[:num_images]):\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_file)\n",
    "        \n",
    "        # Apply correction\n",
    "        corrected_image = apply_correction(image.copy(), spherical_power, cylindrical_power, axis_orientation)\n",
    "        \n",
    "        # Save original and corrected images\n",
    "        save_images(image, corrected_image, output_folder, i+1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get input from the user\n",
    "    input_folder = '/Users/suhas/Documents/Education/Computer Vision/Project/Code/Datasets/Image Captioning/flickr30k_images/flickr30k_images'\n",
    "    output_folder = input(\"Enter the output folder name\")\n",
    "    spherical_power = float(input(\"Enter spherical power (diopters): \"))\n",
    "    cylindrical_power = float(input(\"Enter cylindrical power (diopters): \"))\n",
    "    axis_orientation = float(input(\"Enter axis orientation (degrees): \"))\n",
    "    num_images = int(input(\"Enter the number of images to process: \"))\n",
    "\n",
    "    # Process the images with the given metrics\n",
    "    process_images(input_folder, output_folder, spherical_power, cylindrical_power, axis_orientation, num_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdddd3bb",
   "metadata": {},
   "source": [
    "## Simulating Color Blindness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ce76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def simulate_color_blindness(image_array, type):\n",
    "    # Apply color blindness simulation based on type\n",
    "    if type == 'deuteranomaly':\n",
    "        # Simulate deuteranomaly\n",
    "        image_array = simulate_deuteranomaly(image_array)\n",
    "    elif type == 'protanomaly':\n",
    "        # Simulate protanomaly\n",
    "        image_array = simulate_protanomaly(image_array)\n",
    "    elif type == 'protanopia':\n",
    "        # Simulate protanopia\n",
    "        image_array = simulate_protanopia(image_array)\n",
    "    elif type == 'deuteranopia':\n",
    "        # Simulate deuteranopia\n",
    "        image_array = simulate_deuteranopia(image_array)\n",
    "    elif type == 'tritanomaly':\n",
    "        # Simulate tritanomaly\n",
    "        image_array = simulate_tritanomaly(image_array)\n",
    "    elif type == 'tritanopia':\n",
    "        # Simulate tritanopia\n",
    "        image_array = simulate_tritanopia(image_array)\n",
    "    elif type == 'monochromacy':\n",
    "        # Simulate monochromacy\n",
    "        image_array = simulate_monochromacy(image_array)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def save_images(image_path, simulated_image, output_folder, index):\n",
    "    # Save original image\n",
    "    original_path = os.path.join(output_folder, f'Original_Image_{index}.jpg')\n",
    "    image_path.save(original_path)\n",
    "\n",
    "    # Save simulated image\n",
    "    simulated_path = os.path.join(output_folder, f'Simulated_Image_{index}.jpg')\n",
    "    simulated_image.save(simulated_path)\n",
    "\n",
    "def process_images(input_folder, output_folder, type, num_images):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Get a list of image files in the input folder\n",
    "    image_files = glob.glob(os.path.join(input_folder, '*.jpg'))\n",
    "    \n",
    "    # Process specified number of images\n",
    "    for i, image_file in enumerate(image_files[:num_images]):\n",
    "        # Load the image\n",
    "        image = Image.open(image_file)\n",
    "        \n",
    "        # Convert image to numpy array\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        # Apply color blindness simulation\n",
    "        simulated_array = simulate_color_blindness(image_array.copy(), type)\n",
    "        \n",
    "        # Convert numpy array back to image\n",
    "        simulated_image = Image.fromarray(simulated_array)\n",
    "        \n",
    "        # Save original and simulated images\n",
    "        save_images(image, simulated_image, output_folder, i+1)\n",
    "\n",
    "\n",
    "def simulate_deuteranomaly(image_array):\n",
    "    # Simulate deuteranomaly (make certain shades of green look more red)\n",
    "    # Adjust green component\n",
    "    image_array[:, :, 1] = 0.5 * image_array[:, :, 1] + 0.5 * image_array[:, :, 0]\n",
    "    return image_array\n",
    "\n",
    "def simulate_protanomaly(image_array):\n",
    "    # Simulate protanomaly (make certain shades of red look more green and less bright)\n",
    "    # Adjust red component\n",
    "    image_array[:, :, 0] = 0.5 * image_array[:, :, 0] + 0.5 * image_array[:, :, 1]\n",
    "    # Decrease brightness\n",
    "    image_array *= 0.75\n",
    "    return image_array\n",
    "\n",
    "def simulate_protanopia(image_array):\n",
    "    # Simulate protanopia (unable to tell the difference between red and green at all)\n",
    "    # Set red and green channels to average of blue\n",
    "    average_blue = np.mean(image_array[:, :, 2])\n",
    "    image_array[:, :, 0] = average_blue\n",
    "    image_array[:, :, 1] = average_blue\n",
    "    return image_array\n",
    "\n",
    "def simulate_deuteranopia(image_array):\n",
    "    # Simulate deuteranopia (unable to tell the difference between red and green at all)\n",
    "    # Set red and green channels to average of blue\n",
    "    average_blue = np.mean(image_array[:, :, 2])\n",
    "    image_array[:, :, 0] = average_blue\n",
    "    image_array[:, :, 1] = average_blue\n",
    "    return image_array\n",
    "\n",
    "def simulate_tritanomaly(image_array):\n",
    "    # Simulate tritanomaly (make it hard to tell the difference between blue and green and between yellow and red)\n",
    "    # Reduce blue component\n",
    "    image_array[:, :, 2] *= 0.8\n",
    "    return image_array\n",
    "\n",
    "def simulate_tritanopia(image_array):\n",
    "    # Simulate tritanopia (unable to tell the difference between blue and green, purple and red, and yellow and pink)\n",
    "    # Set blue and green channels to average of red\n",
    "    average_red = np.mean(image_array[:, :, 0])\n",
    "    image_array[:, :, 1] = average_red\n",
    "    image_array[:, :, 2] = average_red\n",
    "    return image_array\n",
    "\n",
    "def simulate_monochromacy(image_array):\n",
    "    # Simulate monochromacy (complete color blindness)\n",
    "    # Convert image to grayscale\n",
    "    grayscale_image = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "    # Expand grayscale to 3 channels\n",
    "    monochrome_image = np.stack((grayscale_image,) * 3, axis=-1)\n",
    "    return monochrome_image\n",
    " \n",
    "image_path = '/Users/suhas/Documents/Education/Computer Vision/Project/Code/static/Assets/images/high res/9.jpg'\n",
    "simulated_image = simulate_color_blindness(image_path, 'tritanophia')\n",
    "cv2.imwrite(\"Simulated.jpg\", simulated_image)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11eaee8",
   "metadata": {},
   "source": [
    "## Image Color Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af752d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "\n",
    "def load_color_dataset(dataset_path):\n",
    "    color_dataset = {}\n",
    "    with open(dataset_path, 'r') as file:\n",
    "        for line in file:\n",
    "            color_name, r, g, b = line.strip().split(',')\n",
    "            color_dataset[(int(r), int(g), int(b))] = color_name\n",
    "    return color_dataset\n",
    "\n",
    "def annotate_colors(image_path, num_colors, color_dataset):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    pixels = image.reshape(-1, 3)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_colors, random_state=42)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    colors = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    pixel_percentages = [count / total_pixels for count in Counter(labels).values()]\n",
    "    sorted_colors = sorted(zip(pixel_percentages, colors), reverse=True)\n",
    "\n",
    "    annotated_image = image.copy()\n",
    "\n",
    "    for pixel_percentage, color in sorted_colors:\n",
    "        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "        mask[labels.reshape(image.shape[:2]) == sorted_colors.index((pixel_percentage, color))] = 255\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if len(contours) == 0 or cv2.contourArea(max(contours, key=cv2.contourArea)) < 100:\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "        cv2.rectangle(annotated_image, (x, y), (x + w, y + h), color.tolist(), 2)\n",
    "\n",
    "        closest_color_name = find_closest_color(color, color_dataset)\n",
    "        cv2.putText(annotated_image, f\"{closest_color_name} ({int(pixel_percentage * 100)}%)\", (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color.tolist(), 2)\n",
    "\n",
    "    return annotated_image\n",
    "\n",
    "def find_closest_color(rgb, color_dataset):\n",
    "    min_dist = float('inf')\n",
    "    closest_color_name = None\n",
    "    for color, name in color_dataset.items():\n",
    "        dist = np.linalg.norm(np.array(rgb) - np.array(color))\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest_color_name = name\n",
    "    return closest_color_name\n",
    "\n",
    "image_path = \"/Users/suhas/Documents/Education/Computer Vision/Project/Code/static/Assets/images/high res/1110.jpg\"\n",
    "num_colors = 5\n",
    "dataset_path = \"/Users/suhas/Documents/Education/Computer Vision/Project/Code/static/Assets/colors-full.csv\" \n",
    "\n",
    "color_dataset = load_color_dataset(dataset_path)\n",
    "annotated_image = annotate_colors(image_path, num_colors, color_dataset)\n",
    "\n",
    "cv2.imwrite('Annotated Image.jpg', annotated_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
